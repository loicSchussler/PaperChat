# PaperChat RAG

Assistant IA pour analyser, indexer et interroger des articles scientifiques en utilisant la technique RAG (Retrieval-Augmented Generation) avec systÃ¨me de conversations persistantes.

## ğŸ¯ FonctionnalitÃ©s

### âœ… ImplÃ©mentÃ©

- **Upload et analyse de PDFs**: Extraction automatique du texte et des mÃ©tadonnÃ©es
- **Extraction de mÃ©tadonnÃ©es**: Titre, auteurs, annÃ©e, abstract et mots-clÃ©s via LLM
- **Chunking intelligent**: DÃ©coupage sÃ©mantique avec LangChain (RecursiveCharacterTextSplitter)
- **Embeddings**: Vectorisation avec text-embedding-3-small (OpenAI/Mammouth AI)
- **Recherche vectorielle**: SimilaritÃ© cosinus avec pgvector
- **Pipeline RAG complet**: GÃ©nÃ©ration de rÃ©ponses contextuelles avec citations des sources
- **DÃ©duplication des sources**: Regroupement intelligent des chunks par article
- **SystÃ¨me de conversations**:
  - Historique persistant des messages
  - MÃ©moire contextuelle (10 derniers messages)
  - Interface type messenger avec sidebar
  - Gestion complÃ¨te (crÃ©ation, lecture, suppression)
- **Monitoring**: Dashboard avec statistiques d'utilisation et coÃ»ts
- **Visualiseur PDF**: IntÃ©grÃ© dans la bibliothÃ¨que

## ğŸ—ï¸ Architecture

- **Backend**: FastAPI (Python 3.11+)
- **Base de donnÃ©es**: PostgreSQL 15 avec extension pgvector
- **Frontend**: Angular 18 avec Angular Material
- **LLM**: Mammouth AI (API compatible OpenAI)
  - GPT-4o-mini pour gÃ©nÃ©ration de texte
  - text-embedding-3-small pour embeddings
- **RAG**: LangChain pour le chunking et le pipeline

## ğŸ“‹ PrÃ©requis

- Docker & Docker Compose
- Node.js 18+ et npm (pour le frontend)
- Python 3.11+ (pour dÃ©veloppement local)
- ClÃ© API Mammouth AI (dÃ©jÃ  configurÃ©e)

## ğŸš€ Installation et DÃ©marrage

### 1. Cloner et configurer

```bash
cd PaperChat
```

### 2. Configurer les variables d'environnement

Copier le fichier `.env.example` vers `.env` :

```bash
cp .env.example .env
```

Ensuite, Ã©diter `.env` et ajouter votre clÃ© API Mammouth AI :

```
OPENAI_API_KEY=votre-clÃ©-api-mammouth
OPENAI_API_BASE=https://api.mammouth.ai/v1
OPENAI_CHAT_MODEL=gpt-4.1-nano
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
```

**Note**:
- Obtenez votre clÃ© API sur [mammouth.ai](https://mammouth.ai)
- Mammouth AI utilise une API compatible OpenAI, donc le code utilise la bibliothÃ¨que `openai` avec un `base_url` personnalisÃ©

### 3. DÃ©marrer avec Docker Compose

```bash
docker-compose up -d
```

Cela va dÃ©marrer :
- PostgreSQL 15 avec pgvector sur le port 5432
- Backend FastAPI sur le port 8000

### 4. CrÃ©er les tables de la base de donnÃ©es

```bash
# Tables principales (papers, chunks, query_logs)
cd backend
python create_db.py

# Tables de conversations (conversations, messages)
docker exec paperchat_backend python run_migration.py
```

**Note**: Le script `run_migration.py` crÃ©e les tables `conversations` et `messages` nÃ©cessaires pour le systÃ¨me de conversations.

### 5. DÃ©marrer le frontend Angular

Dans un nouveau terminal :

```bash
cd frontend
npm install
npm start
```

Le frontend sera accessible sur [http://localhost:4200](http://localhost:4200)

## ğŸ§ª DÃ©veloppement Local (sans Docker)

### Backend

1. Installer les dÃ©pendances Python :

```bash
cd backend
pip install -r requirements.txt
```

2. S'assurer que PostgreSQL avec pgvector est lancÃ© (via Docker ou local):

```bash
docker-compose up -d db
```

3. CrÃ©er les tables :

```bash
python create_db.py
docker exec paperchat_backend python run_migration.py
```

4. Lancer le serveur FastAPI :

```bash
uvicorn app.main:app --reload
```

API accessible sur [http://localhost:8000](http://localhost:8000)
Documentation interactive : [http://localhost:8000/docs](http://localhost:8000/docs)

### Frontend

```bash
cd frontend
npm install
npm start
```

## ğŸ“ Structure du Projet

```
PaperChat/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/              # Endpoints REST
â”‚   â”‚   â”‚   â”œâ”€â”€ papers.py     # Gestion des articles
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py       # Chat RAG
â”‚   â”‚   â”‚   â”œâ”€â”€ conversations.py  # Gestion des conversations
â”‚   â”‚   â”‚   â””â”€â”€ monitoring.py # Statistiques
â”‚   â”‚   â”œâ”€â”€ services/         # Logique mÃ©tier
â”‚   â”‚   â”‚   â”œâ”€â”€ pdf_extractor.py     # Extraction texte PDF
â”‚   â”‚   â”‚   â”œâ”€â”€ metadata_extractor.py # Extraction mÃ©tadonnÃ©es
â”‚   â”‚   â”‚   â”œâ”€â”€ chunker.py           # DÃ©coupage intelligent
â”‚   â”‚   â”‚   â”œâ”€â”€ embeddings.py        # GÃ©nÃ©ration embeddings
â”‚   â”‚   â”‚   â”œâ”€â”€ vector_store.py      # Recherche vectorielle
â”‚   â”‚   â”‚   â””â”€â”€ rag.py              # Pipeline RAG complet
â”‚   â”‚   â”œâ”€â”€ models.py         # ModÃ¨les SQLAlchemy
â”‚   â”‚   â”œâ”€â”€ schemas.py        # SchÃ©mas Pydantic
â”‚   â”‚   â”œâ”€â”€ database.py       # Configuration DB
â”‚   â”‚   â””â”€â”€ main.py          # Application FastAPI
â”‚   â”œâ”€â”€ migrations/           # Scripts de migration SQL
â”‚   â”œâ”€â”€ tests/               # Tests unitaires
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ run_migration.py     # Script de migration
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”œâ”€â”€ pages/        # Pages Angular
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ upload/   # Upload PDFs
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ library/  # BibliothÃ¨que
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ chat/     # Chat RAG
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ dashboard/ # Monitoring
â”‚   â”‚   â”‚   â”œâ”€â”€ services/     # Services API
â”‚   â”‚   â”‚   â””â”€â”€ components/   # Composants rÃ©utilisables
â”‚   â”‚   â””â”€â”€ environments/
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

## ğŸ“Š API Endpoints

### Papers
- `POST /api/papers/upload` - Upload et indexation d'un PDF
- `GET /api/papers` - Liste des articles (avec recherche et filtres)
- `GET /api/papers/{id}` - DÃ©tails d'un article
- `DELETE /api/papers/{id}` - Supprimer un article

### Chat RAG
- `POST /api/chat` - Poser une question avec contexte conversationnel
  - Supporte `conversation_id` pour continuer une conversation
  - CrÃ©Ã© automatiquement une nouvelle conversation si non fourni

### Conversations
- `POST /api/conversations` - CrÃ©er une nouvelle conversation
- `GET /api/conversations` - Liste des conversations (avec pagination)
- `GET /api/conversations/{id}` - DÃ©tails d'une conversation avec messages
- `DELETE /api/conversations/{id}` - Supprimer une conversation
- `PATCH /api/conversations/{id}/title` - Modifier le titre

### Monitoring
- `GET /api/monitoring/stats` - Statistiques d'utilisation (coÃ»ts, performances)

Documentation complÃ¨te : [http://localhost:8000/docs](http://localhost:8000/docs)

## ğŸ¨ Interface Utilisateur

### Pages

- **/upload** : Upload et indexation de PDFs avec barre de progression
- **/library** : BibliothÃ¨que d'articles avec recherche, filtres et visualiseur PDF intÃ©grÃ©
- **/chat** : Interface de conversations type messenger
  - Sidebar avec liste des conversations
  - Historique des messages persistant
  - Bulles de chat (utilisateur / assistant)
  - Affichage des sources avec pertinence
  - MÃ©tadonnÃ©es (temps de rÃ©ponse, coÃ»t)
  - Responsive mobile avec sidebar toggleable
- **/dashboard** : Monitoring en temps rÃ©el
  - Nombre d'articles et chunks
  - Statistiques de requÃªtes
  - CoÃ»ts totaux et moyens
  - Temps de rÃ©ponse moyen

## ğŸ“ Base de DonnÃ©es

### Tables

#### papers
Articles scientifiques avec mÃ©tadonnÃ©es extraites

| Colonne | Type | Description |
|---------|------|-------------|
| id | INTEGER | ClÃ© primaire |
| title | VARCHAR | Titre de l'article |
| authors | TEXT[] | Liste des auteurs |
| year | INTEGER | AnnÃ©e de publication |
| abstract | TEXT | RÃ©sumÃ© |
| keywords | TEXT[] | Mots-clÃ©s |
| nb_chunks | INTEGER | Nombre de chunks |
| created_at | TIMESTAMP | Date d'ajout |

#### chunks
Segments de texte avec embeddings vectoriels (1536D)

| Colonne | Type | Description |
|---------|------|-------------|
| id | INTEGER | ClÃ© primaire |
| paper_id | INTEGER | RÃ©fÃ©rence Ã  papers |
| content | TEXT | Contenu du chunk |
| section_name | VARCHAR | Nom de la section |
| embedding | VECTOR(1536) | Vecteur d'embedding |
| created_at | TIMESTAMP | Date de crÃ©ation |

#### conversations
Sessions de conversations

| Colonne | Type | Description |
|---------|------|-------------|
| id | INTEGER | ClÃ© primaire |
| title | VARCHAR | Titre de la conversation |
| created_at | TIMESTAMP | Date de crÃ©ation |
| updated_at | TIMESTAMP | DerniÃ¨re mise Ã  jour |

#### messages
Messages individuels dans les conversations

| Colonne | Type | Description |
|---------|------|-------------|
| id | INTEGER | ClÃ© primaire |
| conversation_id | INTEGER | RÃ©fÃ©rence Ã  conversations |
| role | VARCHAR | 'user' ou 'assistant' |
| content | TEXT | Contenu du message |
| sources | TEXT | JSON des sources (pour assistant) |
| cost_usd | FLOAT | CoÃ»t de la requÃªte |
| response_time_ms | INTEGER | Temps de rÃ©ponse |
| created_at | TIMESTAMP | Date de crÃ©ation |

#### query_logs
Historique des requÃªtes et mÃ©triques

| Colonne | Type | Description |
|---------|------|-------------|
| id | INTEGER | ClÃ© primaire |
| question | TEXT | Question posÃ©e |
| answer | TEXT | RÃ©ponse gÃ©nÃ©rÃ©e |
| nb_sources | INTEGER | Nombre de sources |
| prompt_tokens | INTEGER | Tokens du prompt |
| completion_tokens | INTEGER | Tokens de complÃ©tion |
| cost_usd | FLOAT | CoÃ»t total |
| response_time_ms | INTEGER | Temps de rÃ©ponse |
| created_at | TIMESTAMP | Date de la requÃªte |

### Extension pgvector

L'extension pgvector permet la recherche de similaritÃ© vectorielle avec l'opÃ©rateur de distance cosinus pour les embeddings 1536D.

## ğŸ§ª Tests

Le projet inclut des tests unitaires complets :

```bash
cd backend
pytest

# Avec couverture
pytest --cov=app

# Tests spÃ©cifiques
pytest tests/test_vector_store.py
pytest tests/test_rag.py
```

**Couverture actuelle**: 45 tests (vector_store + RAG + dÃ©duplication)

## ğŸ”§ Pipeline RAG

### Ã‰tapes du Pipeline

1. **Extraction** : Lecture du PDF et extraction du texte brut
2. **MÃ©tadonnÃ©es** : Extraction via LLM (titre, auteurs, annÃ©e, abstract, keywords)
3. **Chunking** : DÃ©coupage sÃ©mantique avec LangChain (1000 caractÃ¨res, overlap 200)
4. **Embeddings** : Vectorisation des chunks (text-embedding-3-small, 1536D)
5. **Indexation** : Stockage dans PostgreSQL avec pgvector
6. **Recherche** : SimilaritÃ© cosinus pour trouver les chunks pertinents (top-k)
7. **GÃ©nÃ©ration** : LLM gÃ©nÃ¨re la rÃ©ponse avec contexte + historique conversation
8. **DÃ©duplication** : Regroupement des chunks par article source

### FonctionnalitÃ©s AvancÃ©es

- **MÃ©moire contextuelle** : Les 10 derniers messages sont inclus dans le contexte LLM
- **DÃ©duplication intelligente** : Les chunks d'un mÃªme article sont fusionnÃ©s
- **Citations prÃ©cises** : Chaque source inclut le titre, l'annÃ©e, la section et le score de pertinence
- **CoÃ»ts optimisÃ©s** : Calcul prÃ©cis des tokens et coÃ»ts Mammouth AI

## ğŸ’¡ AmÃ©liorations Futures

- [ ] Support de formats additionnels (EPUB, DOCX)
- [ ] Recherche hybride (dense + sparse)
- [ ] Fine-tuning des embeddings
- [ ] Export de conversations
- [ ] Annotations et highlights
- [ ] Partage de conversations
- [ ] Multi-utilisateurs avec authentification
- [ ] AmÃ©lioration de la gÃ©nÃ©ration de titres de conversations
- [ ] Support du streaming pour les rÃ©ponses longues

## ğŸ“š Ressources

- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [pgvector](https://github.com/pgvector/pgvector)
- [LangChain](https://python.langchain.com/)
- [Mammouth AI](https://mammouth.ai) - API compatible OpenAI
- [OpenAI API Documentation](https://platform.openai.com/docs) - Compatible avec Mammouth AI
- [Angular Material](https://material.angular.io/)

## ğŸ“„ Licence

Projet portfolio / Proof of Concept

---

**DÃ©veloppÃ© avec** â¤ï¸ **et Claude Code**
